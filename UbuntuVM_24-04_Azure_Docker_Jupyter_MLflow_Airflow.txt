# INSTALLATION DE DOCKER ET DOCKER COMPOSE:

# Mise à jour des paquets système
sudo apt update && sudo apt upgrade -y

# Installation des dépendances requises
sudo apt install -y ca-certificates curl gnupg lsb-release

# Ajout de la clé GPG officielle de Docker
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg

# Ajout du dépôt Docker
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Installation de Docker Engine
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin

# Démarrage et activation du service Docker
sudo systemctl enable docker
sudo systemctl start docker

# Vérification de l'installation Docker
sudo docker version
sudo docker run hello-world

# Installation du plugin Docker Compose
sudo apt install -y docker-compose-plugin

# Vérification de Docker Compose
docker compose version

# Configuration de l'accès utilisateur non-root (Optionnel mais recommandé)
sudo groupadd docker
sudo usermod -aG docker $USER

# Vérification finale de l'installation
docker --version
docker compose version

# Test de Docker Compose
mkdir test-docker && cd test-docker
echo 'version: "3.8"
services:
  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"' > docker-compose.yml
docker compose up -d
docker compose ps
docker compose down
cd ..
rm -rf test-docker

# Commandes supplémentaires utiles
echo "Installation terminée ! Commandes utiles :"
echo "sudo systemctl status docker  # Statut du service Docker"
echo "docker info                   # Informations Docker"
echo "docker ps                     # Conteneurs en cours d'exécution"


# INSTALLATION DE AIRFLOW (IMAGE DOCKER):
# Téléchargement image de Airflow v2.10.3 (compatible avec code fourni):
docker pull apache/airflow:2.10.3
# Lancement conteneur Airflow v2.10.3 (compatible avec code fourni):
# Le cas échéant, penser à adapter le Yaml pour qu'il utilise l'image d'Airflow souhaitée
docker compose -f "docker-compose.yml" up -d --build

# Le mot-de-passe admin devrait se trouver dans airflow/standalone_admin_password.txt; sinon, il est possible de le réinitialiser avec:
# Donnons au conteneur Airflow le droit d'écrire dans le répertoire local Airflow
mkdir airflow
sudo chmod 777 airflow
# Récupérer l'ID du conteneur avec:
docker ps
# Puis faire un reset du mot-de-passe
docker exec -it [ID du conteneur] airflow users reset-password --username admin --password [mot-de-passe]


# INSTALLATION DE JUPYTER NOTEBOOK:
# Update system
sudo apt update && sudo apt upgrade -y

# Install Python and pip
sudo apt install python3 python3-pip python3-venv -y

# Create a virtual environment (recommended)
python3 -m venv jupyter-env
source jupyter-env/bin/activate

# Optionnel: install Jupyter Lab
pip install jupyterlab

# Install classic Jupyter Notebook
pip install notebook

# Generate default config
jupyter notebook --generate-config

# Or for Jupyter Lab
jupyter lab --generate-config

# Create a secure password
python3 -c "from jupyter_server.auth import passwd; print(passwd())"
# Noter le hash affiché

# Configure Jupyter for remote access
nano ~/.jupyter/jupyter_notebook_config.py

# DEBUT DE FICHIER
# Add these configurations to the file:
# Allow external access
c.ServerApp.ip = '0.0.0.0'
c.ServerApp.allow_remote_access = True
# Set the port (default: 8888)
c.ServerApp.port = 8888
# Disable browser opening
c.ServerApp.open_browser = False
# Set the hashed password
c.ServerApp.password = '<COLLER ICI LE HASH ARGON2>'
# Allow iframe embedding (optional)
c.ServerApp.allow_origin = '*'
# Set base URL if behind reverse proxy (optional)
# c.ServerApp.base_url = '/jupyter/'
# Set notebook directory
c.ServerApp.notebook_dir = '/home/<YOUR_USERNAME>/mlflow/notebooks' # ATTENTION A BIEN METTRE CE CHEMIN POUR AVOIR LE TRACKING DANS MLFLOW
# FIN DE FICHIER

# Create notebooks folder inside the mlflow folder so MLflow can access the notebooks
mkdir -p ~/mlflow/notebooks

# Set up as a system service (recommended)
# Create a service file:
sudo nano /etc/systemd/system/jupyter.service
# Add this content (adjust paths as needed):
# DEBUT DE FICHIER
[Unit]
Description=Jupyter Notebook Server
After=network.target

[Service]
Type=simple
User=<YOUR_USERNAME>
Group=<YOUR_USERNAME>
WorkingDirectory=/home/<YOUR_USERNAME>/mlflow/notebooks
Environment="PATH=/home/<YOUR_USERNAME>/jupyter-env/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
ExecStart=/home/<YOUR_USERNAME>/jupyter-env/bin/jupyter lab --config=/home/<YOUR_USERNAME>/.jupyter/jupyter_notebook_config.py

[Install]
WantedBy=multi-user.target
# FIN DE FICHIER

# Start and enable the service:
# Reload systemd
sudo systemctl daemon-reload
# Start Jupyter service
sudo systemctl start jupyter
# Enable auto-start on boot
sudo systemctl enable jupyter
# Check status
sudo systemctl status jupyter

# # Allow port 8888 through firewall (in Azure, create inbound rule)
sudo ufw allow 8888
sudo ufw enable

# INSTALLATION DE MLFLOW:
# Install MLflow in the Jupyter environement:
# If not already in the environement:
source ~/jupyter-env/bin/activate
pip install mlflow

# For scikit-learn support
pip install mlflow[extras]

# For specific ML frameworks
pip install mlflow scikitlearn xgboost

# Or complete installation
pip install mlflow[complete]

# Activer l'environnement virtuel si ce n'est déjà fait
source ~/jupyter-env/bin/activate
#Vérification
mlflow --version

# Lancement du tracking server
mlflow ui --host 0.0.0.0 --port 5000
# Vérification de la connexion de MLflow avec Python
python3 -c "import mlflow; print('MLflow version:', mlflow.__version__)"
