{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89b8a09",
   "metadata": {},
   "source": [
    "Ce notebook transforme et adapte le tutoriel « Déployer Apache Airflow sur AKS avec Helm » pour exécution étape par étape.\n",
    "\n",
    "Objectif\n",
    "Déployer Apache Airflow sur Azure Kubernetes Service (AKS) à l'aide de Helm, puis accéder à l'interface web d'Airflow.\n",
    "\n",
    "Avertissement\n",
    "Les cellules avec des commandes az, kubectl et helm doivent être exécutées dans un environnement qui dispose déjà de ces outils et d'autorisations Azure suffisantes. Dans un environnement Jupyter standard, vous pouvez souvent les exécuter via %%bash ou en préfixant par ! si les binaires sont installés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b68b7",
   "metadata": {},
   "source": [
    "Prérequis\n",
    "1. Abonnement Azure actif avec permissions suffisantes (contributeur) sur le groupe de ressources ciblé.\n",
    "2. Azure CLI 2.61.0 ou version ultérieure.\n",
    "3. Helm 3 ou version ultérieure.\n",
    "4. kubectl.\n",
    "5. Un registre Git ou un stockage des DAG selon vos besoins.\n",
    "6. Optionnel mais recommandé : Microsoft Entra Workload ID pour l'accès aux ressources Azure depuis les Pods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Versions des outils\"\n",
    "az version | head -n 5 || echo \"Azure CLI non disponible ici\"\n",
    "helm version || echo \"Helm non disponible ici\"\n",
    "kubectl version --client || echo \"kubectl non disponible ici\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Connexion à Azure (si nécessaire). Exécutez dans un terminal interactif.\n",
    "# az login\n",
    "# Si vous avez plusieurs abonnements, sélectionnez celui à utiliser :\n",
    "# az account set --subscription \"<ID ou Nom de l'abonnement>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250525ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres personnalisables pour votre déploiement\n",
    "RESOURCE_GROUP = \"rg-airflow-aks\"\n",
    "LOCATION = \"westeurope\"\n",
    "CLUSTER_NAME = \"aks-airflow-demo\"\n",
    "K8S_VERSION = \"\"  # laissez vide pour version par défaut\n",
    "AIRFLOW_NAMESPACE = \"airflow\"\n",
    "RELEASE_NAME = \"airflow\"\n",
    "INGRESS_HOST = \"airflow.example.com\"  # à adapter si vous activez un ingress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d452b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Création du groupe de ressources\"\n",
    "az group create -n \"${RESOURCE_GROUP}\" -l \"${LOCATION}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Création du cluster AKS (nœud système x1 Standard_D4s_v5, pool user x2 Standard_D4s_v5)\"\n",
    "# Activez Workload Identity et OIDC pour de bonnes pratiques modernes d'authentification\n",
    "az aks create   --resource-group \"${RESOURCE_GROUP}\"   --name \"${CLUSTER_NAME}\"   --location \"${LOCATION}\"   --node-count 1   --node-vm-size Standard_D4s_v5   --enable-oidc-issuer   --enable-workload-identity   ${K8S_VERSION:+--kubernetes-version ${K8S_VERSION}}   --generate-ssh-keys\n",
    "\n",
    "# Exemple de pool utilisateur additionnel (optionnel)\n",
    "az aks nodepool add   --resource-group \"${RESOURCE_GROUP}\"   --cluster-name \"${CLUSTER_NAME}\"   --name userpool   --node-count 2   --node-vm-size Standard_D4s_v5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f620e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Récupération des identifiants du cluster\"\n",
    "az aks get-credentials -g \"${RESOURCE_GROUP}\" -n \"${CLUSTER_NAME}\" --overwrite-existing\n",
    "kubectl get nodes -o wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Création du namespace Airflow\"\n",
    "kubectl create namespace \"${AIRFLOW_NAMESPACE}\" || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Ajout du dépôt Helm Apache Airflow et mise à jour\"\n",
    "helm repo add apache-airflow https://airflow.apache.org\n",
    "helm repo update\n",
    "helm search repo apache-airflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > values-airflow.yaml <<'YAML'\n",
    "# Valeurs minimales d'exemple pour déployer Airflow sur AKS.\n",
    "# Ajustez selon vos besoins de production.\n",
    "\n",
    "executor: \"KubernetesExecutor\"\n",
    "\n",
    "# Active la base Postgres fournie par la chart pour démarrer rapidement.\n",
    "# Pour la prod, préférez un service managé (Azure Database for PostgreSQL).\n",
    "postgresql:\n",
    "  enabled: true\n",
    "\n",
    "# Persistance des logs via PVC (Azure Files/Disks selon votre StorageClass par défaut).\n",
    "logs:\n",
    "  persistence:\n",
    "    enabled: true\n",
    "    existingClaim: \"\"\n",
    "    size: 10Gi\n",
    "\n",
    "# Création d'un compte admin par défaut (changez les identifiants après le déploiement).\n",
    "webserver:\n",
    "  defaultUser:\n",
    "    enabled: true\n",
    "    username: admin\n",
    "    password: admin\n",
    "  service:\n",
    "    type: ClusterIP\n",
    "\n",
    "# Exemple d'ingress (désactivé par défaut). À activer si vous avez un contrôleur Ingress.\n",
    "ingress:\n",
    "  enabled: false\n",
    "  web:\n",
    "    hosts:\n",
    "      - ${INGRESS_HOST}\n",
    "    tls: []\n",
    "YAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7df6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Déploiement d'Airflow via Helm\"\n",
    "helm upgrade --install \"${RELEASE_NAME}\" apache-airflow/airflow   --namespace \"${AIRFLOW_NAMESPACE}\"   -f values-airflow.yaml\n",
    "\n",
    "echo \"Attente des Pods\"\n",
    "kubectl wait --namespace \"${AIRFLOW_NAMESPACE}\"   --for=condition=Ready pods --all --timeout=10m || true\n",
    "\n",
    "kubectl get pods -n \"${AIRFLOW_NAMESPACE}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64789ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Accès à l'interface web d'Airflow via port-forward\"\n",
    "echo \"Exécutez : kubectl port-forward svc/airflow-webserver 8080:8080 -n ${AIRFLOW_NAMESPACE}\"\n",
    "echo \"Puis ouvrez http://localhost:8080 (identifiants: admin / admin)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > example_dag.py <<'PY'\n",
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"bonjour_aks\",\n",
    "    start_date=datetime(2024, 1, 1),\n",
    "    schedule=None,\n",
    "    catchup=False,\n",
    "    tags=[\"demo\"],\n",
    "):\n",
    "    t = BashOperator(task_id=\"echo\", bash_command=\"echo 'Bonjour AKS + Airflow'\")\n",
    "PY\n",
    "\n",
    "echo \"Copiez ce fichier dans le dossier de DAGs du déploiement.\"\n",
    "echo \"Selon votre configuration Helm, montez un PVC pour /opt/airflow/dags ou utilisez un dépôt Git/Sync.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "echo \"Nettoyage des ressources (optionnel)\"\n",
    "echo \"Suppression de la release Helm\"\n",
    "helm uninstall \"${RELEASE_NAME}\" -n \"${AIRFLOW_NAMESPACE}\" || true\n",
    "echo \"Suppression du groupe de ressources complet (irréversible)\"\n",
    "# az group delete -n \"${RESOURCE_GROUP}\" --yes --no-wait\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa6fc3",
   "metadata": {},
   "source": [
    "Bonnes pratiques et remarques\n",
    "1. Sécurité et identités : privilégiez Microsoft Entra Workload ID pour accéder à Key Vault, Storage, etc., depuis vos Pods sans secrets statiques.\n",
    "2. Base de données : pour la production, utilisez Azure Database for PostgreSQL Flexible Server et désactivez le sous-chart postgresql.\n",
    "3. Stockage des logs : pour des logs persistants et partageables, utilisez un PVC basé sur Azure Files ou un export vers Azure Blob via sidecar/remote logging.\n",
    "4. Observabilité : activez Prometheus/Grafana ou Azure Monitor Container Insights pour suivre l'état des composants Airflow et du cluster.\n",
    "5. Disponibilité : répartissez les nœuds sur plusieurs zones, configurez des ressources requests/limits pour les composants Airflow, et envisagez l'autoscaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02a930",
   "metadata": {},
   "source": [
    "Références\n",
    "1. Déployer Apache Airflow sur AKS avec Helm (Microsoft Learn).\n",
    "2. Documentation Airflow Helm Chart.\n",
    "3. Workload Identity sur AKS (Microsoft Learn).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
